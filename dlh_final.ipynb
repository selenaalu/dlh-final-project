{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Heart Disease Detection via Multi-View MIL: SAMIL Reproduction\n",
        "\n",
        "Huang, Z., Wessler, B. S., & Hughes, M. C. (2023). Detecting Heart Disease from Multi-View Ultrasound Images via Supervised Attention Multiple Instance Learning. Proceedings of the 8th Machine Learning for Healthcare Conference, PMLR 219:285â€“307."
      ],
      "metadata": {
        "id": "zoC7dxHv1P4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-metric-learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sypkb9uzb-4",
        "outputId": "915e3661-a3ff-4222-d77b-e9fb46055e9c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-metric-learning) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pytorch-metric-learning) (1.6.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-metric-learning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pytorch-metric-learning) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pytorch-metric-learning) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pytorch-metric-learning) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk8C64MPtg9o",
        "outputId": "790c03fd-8295-412f-82e7-2ee6de8a6e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Standard Libraries ===\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import logging\n",
        "from collections import defaultdict\n",
        "\n",
        "# === Data Handling ===\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# === PyTorch and TorchVision ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# === Metric Learning ===\n",
        "from pytorch_metric_learning import losses\n",
        "\n",
        "# === Sklearn Utilities ===\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# === Progress Display ===\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Local Project Code ===\n",
        "sys.path.append('/content/gdrive/MyDrive/dlh project/SAMIL/src/SAMIL/')\n",
        "from libml.models.view_classifier import build_wideresnet"
      ],
      "metadata": {
        "id": "TzLzuYEah1d7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "ZjmIGCRLhyho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "data_dir = '/content/gdrive/MyDrive/dlh project/view_and_diagnosis_labeled_set'\n",
        "labeled_dir = os.path.join(data_dir, 'labeled')\n",
        "unlabeled_dir = os.path.join(data_dir, 'unlabeled')\n",
        "labels_csv = os.path.join(data_dir, 'labels_per_image.csv')\n",
        "\n",
        "# Load CSV with labels\n",
        "labels_df = pd.read_csv(labels_csv)\n",
        "\n",
        "# Filter labels_df to include only existing files in the labeled directory\n",
        "labels_df = labels_df[labels_df['query_key'].apply(lambda x: os.path.isfile(os.path.join(labeled_dir, x)))].reset_index(drop=True)\n",
        "\n",
        "# Function to extract study_id from filename\n",
        "def extract_study_id(query_key):\n",
        "    return query_key.split('_')[0]  # e.g., '3407s1' from '3407s1_0.png'\n",
        "\n",
        "# Apply function to dataframe\n",
        "labels_df['study_id'] = labels_df['query_key'].apply(extract_study_id)\n",
        "\n",
        "# Clean labels\n",
        "labels_df['view_label'] = labels_df['view_label'].str.strip()\n",
        "labels_df['diagnosis_label'] = labels_df['diagnosis_label'].str.strip()\n",
        "\n",
        "# Create mapping: image path -> labels (for supervised learning)\n",
        "image_to_labels = {}\n",
        "for _, row in labels_df.iterrows():\n",
        "    img_filename = row['query_key']\n",
        "    img_path = os.path.join(labeled_dir, img_filename)\n",
        "    image_to_labels[img_path] = {\n",
        "        \"view_label\": row['view_label'],\n",
        "        \"diagnosis_label\": row['diagnosis_label']\n",
        "    }\n",
        "\n",
        "# Get all image filenames in the unlabeled directory\n",
        "unlabeled_image_paths = [os.path.join(unlabeled_dir, filename) for filename in os.listdir(unlabeled_dir) if os.path.isfile(os.path.join(unlabeled_dir, filename))]\n",
        "\n",
        "# Create mapping: study_id -> list of image paths (for contrastive learning)\n",
        "study_to_images = defaultdict(list)\n",
        "for img_path in unlabeled_image_paths:\n",
        "    study_id = extract_study_id(os.path.basename(img_path))\n",
        "    study_to_images[study_id].append(img_path)"
      ],
      "metadata": {
        "id": "PUsWf3uXxa1H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EchoDataset(Dataset):\n",
        "    def __init__(self, image_paths, image_to_labels=None, transform=None, augment_transform=None, all_view_labels=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_paths (list): List of image file paths.\n",
        "            image_to_labels (dict, optional): Mapping from image path to labels.\n",
        "            transform (callable, optional): Optional transform to be applied on an image (e.g., resize and to tensor).\n",
        "            augment_transform (callable, optional): Optional transform for augmenting images (e.g., random crop, flip).\n",
        "            all_view_labels (list, optional): List of all possible view labels for label encoding.\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.image_to_labels = image_to_labels\n",
        "        self.transform = transform\n",
        "        self.augment_transform = augment_transform\n",
        "\n",
        "        # Initialize LabelEncoder\n",
        "        self.view_label_encoder = LabelEncoder()\n",
        "        self.diagnosis_label_encoder = LabelEncoder()\n",
        "\n",
        "        # Fit the LabelEncoder with all unique view labels from your dataset if image_to_labels is provided\n",
        "        if image_to_labels is not None:  # Check if image_to_labels is provided\n",
        "            all_view_labels = list(set(v['view_label'] for v in image_to_labels.values()))\n",
        "            self.view_label_encoder.fit(all_view_labels)  # Fit the encoder\n",
        "            all_diagnosis_labels = list(set(v['diagnosis_label'] for v in image_to_labels.values()))\n",
        "            self.diagnosis_label_encoder.fit(all_diagnosis_labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Apply augmentations first\n",
        "        view1 = self.augment_transform(image) if self.augment_transform else image\n",
        "        view2 = self.augment_transform(image) if self.augment_transform else image\n",
        "\n",
        "        # Now apply the usual transforms (like resizing and converting to tensor)\n",
        "        if self.transform:\n",
        "            view1 = self.transform(view1)\n",
        "            view2 = self.transform(view2)\n",
        "\n",
        "        if self.image_to_labels:\n",
        "            labels = self.image_to_labels.get(img_path, {})\n",
        "            view_label = labels.get('view_label')\n",
        "            diagnosis_label = labels.get('diagnosis_label')\n",
        "\n",
        "            # Encode the labels\n",
        "            view_label = self.view_label_encoder.transform([view_label])[0]\n",
        "            diagnosis_label = self.diagnosis_label_encoder.transform([diagnosis_label])[0]\n",
        "\n",
        "            return view1, view2, view_label, diagnosis_label\n",
        "        else:\n",
        "            return view1, view2"
      ],
      "metadata": {
        "id": "zOWpSbH0ZSdm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of image paths with labels\n",
        "labeled_image_paths = list(image_to_labels.keys())\n",
        "\n",
        "# Flatten the list of image paths from all studies\n",
        "unlabeled_image_paths = [img_path for images in study_to_images.values() for img_path in images]\n",
        "\n",
        "# Define base transformations (resize and to tensor)\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Define augmentation transformations (e.g., random horizontal flip, rotation, etc.)\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    #transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create the supervised dataset with augmentations\n",
        "supervised_dataset = EchoDataset(\n",
        "    image_paths=labeled_image_paths,\n",
        "    image_to_labels=image_to_labels,\n",
        "    transform=base_transform,\n",
        "    augment_transform=augment_transform\n",
        ")\n",
        "\n",
        "# Create the self-supervised dataset with augmentations\n",
        "self_supervised_dataset = EchoDataset(\n",
        "    image_paths=unlabeled_image_paths,\n",
        "    transform=base_transform,  # Base transform for resizing and tensor conversion\n",
        "    augment_transform=augment_transform  # Augmentation for self-supervised learning\n",
        ")\n"
      ],
      "metadata": {
        "id": "uECGsGJVYxUs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sizes for training, validation, and test sets\n",
        "total_size = len(supervised_dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "test_size = total_size - train_size - val_size  # Ensures all data is used\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    supervised_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "# Create DataLoaders for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the sizes for training, validation, and test sets\n",
        "unlabeled_total_size = len(self_supervised_dataset)\n",
        "unlabeled_train_size = int(0.8 * unlabeled_total_size)\n",
        "unlabeled_val_size = int(0.1 * unlabeled_total_size)\n",
        "unlabeled_test_size = unlabeled_total_size - unlabeled_train_size - unlabeled_val_size\n",
        "\n",
        "# Split the dataset\n",
        "unlabeled_train_dataset, unlabeled_val_dataset, unlabeled_test_dataset = random_split(\n",
        "    self_supervised_dataset, [unlabeled_train_size, unlabeled_val_size, unlabeled_test_size]\n",
        ")\n",
        "\n",
        "# Create DataLoaders for each set\n",
        "unlabeled_train_loader = DataLoader(unlabeled_train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "unlabeled_val_loader = DataLoader(unlabeled_val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
        "unlabeled_test_loader = DataLoader(unlabeled_test_dataset, batch_size=8, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6gYu8cTZ0e8",
        "outputId": "434b4844-14c5-4ecf-9370-4fe8834a822e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "8OpMnPZEkAYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain(model, pretrain_loader, contrastive_loss_fn, optimizer, device, num_epochs=100):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        for batch in pretrain_loader:\n",
        "            study_view1, study_view2 = batch\n",
        "\n",
        "            study_view1 = study_view1.to(device)\n",
        "            study_view2 = study_view2.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            z1, _ = model(study_view1)\n",
        "            z2, _ = model(study_view2)\n",
        "\n",
        "            # Concatenate embeddings and create labels\n",
        "            embeddings = torch.cat([z1, z2], dim=0)\n",
        "            labels = torch.arange(z1.size(0)).to(device)\n",
        "            labels = torch.cat([labels, labels], dim=0)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = contrastive_loss_fn(embeddings, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Pretraining Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(pretrain_loader):.4f}')\n"
      ],
      "metadata": {
        "id": "p_2LSEcwZ2p7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def create_view_relevance_classifier():\n",
        "    base_model = build_wideresnet(depth=28, widen_factor=2, dropout=0.0, num_classes=3) # Original view model\n",
        "\n",
        "    logger.info(\"Total params for View Model: {:.2f}M\".format(\n",
        "        sum(p.numel() for p in base_model.parameters()) / 1e6))\n",
        "\n",
        "    checkpoint_path = '/content/gdrive/MyDrive/dlh project/seed0_model_best.pth.tar'\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
        "    base_model.load_state_dict(checkpoint['ema_state_dict'])\n",
        "    base_model.eval()\n",
        "\n",
        "    # Modify the final layer to output a single probability score\n",
        "    base_model.fc = nn.Sequential(\n",
        "        nn.Linear(base_model.fc.in_features, 1),  # Output a single probability\n",
        "        nn.Sigmoid()  # Apply sigmoid to get probability between 0 and 1\n",
        "    )\n",
        "\n",
        "    return base_model  # Return the modified view model as the relevance classifier\n",
        "\n",
        "def supervised_attention_loss(attention_weights, relevance_scores, tau_v=1.0):\n",
        "    \"\"\"\n",
        "    Calculates the supervised attention loss (LSA) as described in Equation (4).\n",
        "\n",
        "    Args:\n",
        "        attention_weights (torch.Tensor): Attention weights (A) produced by the model.\n",
        "        relevance_scores (torch.Tensor): Relevance scores (R) from the view relevance classifier.\n",
        "        tau_v (float): Temperature scaling parameter for the softmax transform.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The supervised attention loss.\n",
        "    \"\"\"\n",
        "    # Calculate R (relevance probabilities) using softmax with temperature scaling\n",
        "    relevance_probabilities = torch.softmax(relevance_scores / tau_v, dim=0)\n",
        "\n",
        "    # Calculate KL divergence between R and A\n",
        "    loss = torch.nn.functional.kl_div(\n",
        "        torch.log(attention_weights),\n",
        "        relevance_probabilities,\n",
        "        reduction='batchmean'  # You can change the reduction method if needed\n",
        "    )\n",
        "\n",
        "    return loss\n",
        "\n",
        "class LMFLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=0.25):\n",
        "        super(LMFLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "def train_model_with_attention(model, train_loader, val_loader, criterion, attention_loss_fn, optimizer, num_epochs=25, device='cuda', lambda_attention=1.0):\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5\n",
        "    trigger_times = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs1, inputs2, view_label, diagnosis_label in tqdm(train_loader): # Unpack all 4 values\n",
        "            inputs = torch.cat([inputs1, inputs2], dim=0) # Concatenate view1 and view2 along dimension 0 to create inputs\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # Repeat labels to match the concatenated input size\n",
        "            labels = torch.tensor(diagnosis_label, device=device).repeat(2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs, attention_weights = model(inputs)\n",
        "            classification_loss = criterion(outputs, labels)\n",
        "\n",
        "            # Calculate supervised attention loss\n",
        "            view_relevance_classifier = create_view_relevance_classifier().to(device) # Initialize the view relevance classifier\n",
        "            relevance_scores = view_relevance_classifier(inputs) # Get relevance scores from the classifier\n",
        "            attention_loss = supervised_attention_loss(attention_weights, relevance_scores) # Calculate supervised attention loss\n",
        "\n",
        "            # Calculate total loss\n",
        "            loss = classification_loss + lambda_attention * attention_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Training Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs1, inputs2, view_label, diagnosis_label in tqdm(val_loader):\n",
        "                inputs = torch.cat([inputs1, inputs2], dim=0)\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                # Repeat labels to match the concatenated input size\n",
        "                labels = torch.tensor(diagnosis_label, device=device).repeat(2)\n",
        "\n",
        "                outputs, attention_weights = model(inputs)\n",
        "                classification_loss = criterion(outputs, labels)\n",
        "\n",
        "                # Assuming you have a way to get view_relevance_scores for validation data\n",
        "                # Replace this with your actual logic to get relevance scores\n",
        "                view_relevance_classifier = create_view_relevance_classifier().to(device)\n",
        "                relevance_scores = view_relevance_classifier(inputs)\n",
        "\n",
        "                attention_loss = attention_loss_fn(attention_weights, relevance_scores)\n",
        "                loss = classification_loss + lambda_attention * attention_loss\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
        "        print(f'Validation Loss: {val_epoch_loss:.4f}')\n",
        "\n",
        "        # Early stopping\n",
        "        if val_epoch_loss < best_val_loss:\n",
        "            best_val_loss = val_epoch_loss\n",
        "            trigger_times = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print('Early stopping!')\n",
        "                break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "kikyjKByZ8uQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom model integrating ResNet and attention mechanism\n",
        "class ResNetWithAttention(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(ResNetWithAttention, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "\n",
        "        # Attention mechanism (could be a simple attention layer)\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(num_classes, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet(x)\n",
        "        attention_weights = torch.sigmoid(self.attention(features))  # Apply attention (between 0 and 1)\n",
        "        return features, attention_weights"
      ],
      "metadata": {
        "id": "sCuwESw2d-zX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization\n",
        "model = ResNetWithAttention(num_classes=5)\n",
        "\n",
        "# Loss functions and optimizer\n",
        "criterion = LMFLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "contrastive_loss_fn = losses.ContrastiveLoss()\n",
        "attention_loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "DoDC2d2aeScu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b943e6-f5f9-4ef5-e1a6-7d4de1d6a045"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Training Process:\n",
        "def train_with_both_labeled_and_unlabeled(model, labeled_train_loader, labeled_val_loader, unlabeled_loader, criterion, attention_loss_fn, contrastive_loss_fn, optimizer, num_epochs=100, device='cuda', lambda_attention=1.0):\n",
        "    # Step 1: Pretrain on Unlabeled Data\n",
        "    print(\"Starting pretraining on unlabeled data...\")\n",
        "    pretrain(model, unlabeled_loader, contrastive_loss_fn, optimizer, device, num_epochs=num_epochs)\n",
        "\n",
        "    # Step 2: Fine-tune on Labeled Data\n",
        "    print(\"Starting fine-tuning on labeled data...\")\n",
        "    model = train_model_with_attention(model, labeled_train_loader, labeled_val_loader, criterion, attention_loss_fn, optimizer, num_epochs=num_epochs, device=device, lambda_attention=lambda_attention)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "nVW5kdvex4Qy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using both labeled and unlabeled data\n",
        "trained_model = train_with_both_labeled_and_unlabeled(model, train_loader, val_loader, unlabeled_train_loader, criterion, attention_loss_fn, contrastive_loss_fn, optimizer, num_epochs=20, device='cuda', lambda_attention=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvXsyoTkycnO",
        "outputId": "1edca088-460d-4d04-804f-7c294abfef1f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting pretraining on unlabeled data...\n",
            "Pretraining Epoch [1/20], Loss: 0.9592\n",
            "Pretraining Epoch [2/20], Loss: 0.8084\n",
            "Pretraining Epoch [3/20], Loss: 0.7412\n",
            "Pretraining Epoch [4/20], Loss: 0.6663\n",
            "Pretraining Epoch [5/20], Loss: 0.6349\n",
            "Pretraining Epoch [6/20], Loss: 0.5831\n",
            "Pretraining Epoch [7/20], Loss: 0.5610\n",
            "Pretraining Epoch [8/20], Loss: 0.5557\n",
            "Pretraining Epoch [9/20], Loss: 0.5276\n",
            "Pretraining Epoch [10/20], Loss: 0.5116\n",
            "Pretraining Epoch [11/20], Loss: 0.4843\n",
            "Pretraining Epoch [12/20], Loss: 0.4797\n",
            "Pretraining Epoch [13/20], Loss: 0.4623\n",
            "Pretraining Epoch [14/20], Loss: 0.4668\n",
            "Pretraining Epoch [15/20], Loss: 0.4542\n",
            "Pretraining Epoch [16/20], Loss: 0.4293\n",
            "Pretraining Epoch [17/20], Loss: 0.4371\n",
            "Pretraining Epoch [18/20], Loss: 0.4389\n",
            "Pretraining Epoch [19/20], Loss: 0.4032\n",
            "Pretraining Epoch [20/20], Loss: 0.4008\n",
            "Starting fine-tuning on labeled data...\n",
            "Epoch 1/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]<ipython-input-9-4e405c337fb9>:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(diagnosis_label, device=device).repeat(2)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]<ipython-input-9-4e405c337fb9>:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(diagnosis_label, device=device).repeat(2)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6913\n",
            "Epoch 2/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6220\n",
            "Epoch 3/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6067\n",
            "Epoch 4/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5855\n",
            "Epoch 5/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5687\n",
            "Epoch 6/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5523\n",
            "Epoch 7/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5282\n",
            "Epoch 8/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5152\n",
            "Epoch 9/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5289\n",
            "Epoch 10/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5372\n",
            "Epoch 11/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5090\n",
            "Epoch 12/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5031\n",
            "Epoch 13/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5165\n",
            "Epoch 14/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5169\n",
            "Epoch 15/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4969\n",
            "Epoch 16/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4957\n",
            "Epoch 17/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4999\n",
            "Epoch 18/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5084\n",
            "Epoch 19/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4940\n",
            "Epoch 20/20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model"
      ],
      "metadata": {
        "id": "sfFut9Z2Yi_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs1, inputs2, view_label, diagnosis_label in test_loader:\n",
        "        # Concatenate inputs from both views\n",
        "        inputs1 = inputs1.to(device)\n",
        "        inputs2 = inputs2.to(device)\n",
        "        inputs = torch.cat([inputs1, inputs2], dim=0)\n",
        "\n",
        "        # Repeat labels to match the concatenated input size\n",
        "        labels = torch.tensor(diagnosis_label, device=device).repeat(2)\n",
        "\n",
        "        outputs, attention_weights = trained_model(inputs)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute balanced accuracy for multiclass classification\n",
        "balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
        "print(f'Balanced Accuracy: {balanced_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzq7kMVZffFU",
        "outputId": "2cab5084-483e-49a6-c5da-3cea13f7969d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-e7ce377575d3>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(diagnosis_label, device=device).repeat(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Accuracy: 0.2254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming your label encoder is available as view_label_encoder\n",
        "class_names = supervised_dataset.diagnosis_label_encoder.classes_  # Update if you use a different encoder\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ymOx3Wian_UK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "7963e562-ba4e-46e0-cce9-cb751731262d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hAdHGOeQO2kB",
        "outputId": "0c3cc3c9-9485-44ad-d6ca-835df261f138"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7de8e7a3-5425-4fb9-8e7a-19cbe6a306a9\", \"best_model.pth\", 94398146)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mf3AbninYJFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}